{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>PROGRAM</u>**\n",
    "\n",
    "import nltk  \n",
    "from nltk.tokenize import word_tokenize  \n",
    "corpus=eval(input(\"Enter the corpus:\"))  \n",
    "dict={}  \n",
    "for i in range(len(corpus)):  \n",
    "str=word_tokenize(corpus\\[i\\])  \n",
    "for j in str:  \n",
    "if j in dict:  \n",
    "dict\\[j\\]+=1  \n",
    "else:  \n",
    "dict\\[j\\]=1  \n",
    "print(dict)  \n",
    "dict={}\n",
    "\n",
    "**<u>OUTPUT</u>**\n",
    "\n",
    "{'This': 1, 'is': 1, 'the': 1, 'first': 1, 'document': 1}\n",
    "\n",
    "{'This': 1, 'document': 2, 'is': 1, 'the': 1, 'second': 1}\n",
    "\n",
    "{'Last': 1, 'document': 2, 'is': 1, 'the': 1, 'third': 1}"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
